{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## I. High-Priority Model Performance Monitoring\n",
        "\n",
        "This code uses the **Boto3** library to create an **Amazon CloudWatch Alarm** that monitors the performance of a live machine learning model. Specifically, it tracks the **F2 Score**—a critical metric for models where missing a \"positive\" result is dangerous or costly.\n",
        "\n",
        " It ensures that the model remains effective at identifying the specific events it was trained to find, such as fraudulent transactions or security threats.\n",
        "---\n",
        "\n",
        "### 1. The Core Metric: Understanding the F2 Score\n",
        "\n",
        "The **F2 Score** is a specialized version of the more common F1 score. While most metrics try to balance \"accuracy\" and \"completeness,\" the F2 score is weighted heavily toward **Recall**.\n",
        "\n",
        "* **Why it matters:** In fields like cybersecurity or medical diagnostics, a \"False Negative\" (missing a real threat) is much worse than a \"False Positive\" (a false alarm).\n",
        "* **The Goal:** An F2 score of **1.0** is perfect. This script ensures that the model doesn't drift into a state where it starts missing too many important events.\n",
        "\n",
        "### 2. Guarding the \"Quality\" Threshold\n",
        "\n",
        "The code establishes a performance floor for your SageMaker model.\n",
        "\n",
        "* **The Limit (0.8):** The script sets a threshold of **0.8**. If the model's ability to capture true positives drops below this level, it is considered a significant failure in model quality.\n",
        "* **Namespace:** It looks specifically in the `model-quality` area of your SageMaker logs. This distinguishes this alarm from others that might monitor hardware issues (like CPU) or data issues (like formatting).\n",
        "\n",
        "### 3. Continuous Hourly Surveillance\n",
        "\n",
        "Machine learning models can \"decay\" over time as the real world changes. This script handles that by:\n",
        "\n",
        "* **Hourly Checks:** It evaluates the average F2 score every **60 minutes** (`Period=3600`).\n",
        "* **Statistical Rigor:** It uses the **Average** score over that hour to ensure the alarm doesn't trigger over a single weird data point, but rather a genuine trend in poor performance.\n",
        "\n",
        "### 4. Automated Incident Response\n",
        "\n",
        "The script ensures that the engineering team is the first to know if the model fails.\n",
        "\n",
        "* **The Alert (SNS):** If the score drops below 0.8, a notification is instantly sent via the **Simple Notification Service (SNS)**. This can be routed to an email, a SMS, or a pager.\n",
        "* **The Recovery Signal:** When the model is fixed or the score rises back above 0.8, a \"Clear\" notification is sent, allowing the team to stand down.\n",
        "\n",
        "### 5. Precision Identification\n",
        "\n",
        "The alarm is laser-focused on a specific **SageMaker Endpoint**. By using the `EndpointName` as a dimension, the script ensures that you aren't getting general alerts; you are getting a specific diagnosis of exactly which model is underperforming.\n"
      ],
      "metadata": {
        "id": "h2GO48voVJEE"
      },
      "id": "h2GO48voVJEE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a00596ec-b231-40b9-8a17-ad2873597f21",
      "metadata": {
        "id": "a00596ec-b231-40b9-8a17-ad2873597f21",
        "outputId": "2f2a2f63-94ed-4a15-8333-ec98521d4f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Alarm 'ueba-endpoint2026216-v2-F2-Low' created.\n"
          ]
        }
      ],
      "source": [
        "# I. High-Priority Model Performance Monitoring\n",
        "import boto3\n",
        "\n",
        "cloudwatch = boto3.client('cloudwatch')\n",
        "endpoint_name = \"ueba-endpoint2026216-v2\"\n",
        "alarm_name = f\"{endpoint_name}-F2-Low\"\n",
        "sns_topic_arn = \"arn:aws:sns:us-east-1:805801076223:YourSNSTopic\"  # <-- Replace with your SNS topic ARN\n",
        "\n",
        "cloudwatch.put_metric_alarm(\n",
        "    AlarmName=alarm_name,\n",
        "    AlarmDescription=f'Alarm when F2 score drops below 0.8 for endpoint {endpoint_name}',\n",
        "    ActionsEnabled=True,\n",
        "    OKActions=[sns_topic_arn],\n",
        "    AlarmActions=[sns_topic_arn],\n",
        "    MetricName='f2',\n",
        "    Namespace='aws/sagemaker/Endpoints/model-quality',\n",
        "    Statistic='Average',\n",
        "    Dimensions=[\n",
        "        {'Name': 'EndpointName', 'Value': endpoint_name}\n",
        "    ],\n",
        "    Period=3600,          # 1 hour (monitoring runs hourly)\n",
        "    EvaluationPeriods=1,\n",
        "    Threshold=0.8,\n",
        "    ComparisonOperator='LessThanThreshold'\n",
        ")\n",
        "print(f\"✅ Alarm '{alarm_name}' created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## II. Automated Data Quality and Feature Drift Monitoring\n",
        "\n",
        "This script acts as a \"digital health monitor\" for the information being fed into your AI model. It focuses on **Feature Drift**, which is a critical signal that your model might be starting to fail because the real world has changed since the model was trained.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. The Core Objective: Detecting \"Stale\" Data\n",
        "\n",
        "AI models are like students who studied for an exam using a specific textbook. **Feature Drift** happens when the \"exam\" (real-world data) starts using questions or topics that weren't in the \"textbook\" (training data).\n",
        "\n",
        "For example, if a model was trained to predict house prices based on interest rates of **3%**, but interest rates suddenly climb to **8%**, the \"interest rate\" feature has drifted. This script detects that gap before the model starts making wild, inaccurate guesses.\n",
        "\n",
        "### 2. Monitoring the \"Ingredients\" of AI\n",
        "\n",
        "Rather than looking at the model's final answer, this code inspects the \"ingredients\"—the individual data points (features) used to make a prediction.\n",
        "\n",
        "* **Targeting the Endpoint:** It identifies the specific live model (the \"Endpoint\") to watch.\n",
        "* **The Specific Metric:** It tracks a value called `feature_baseline_drift`. This is a mathematical score that calculates how different today's data looks compared to the data used during training.\n",
        "* **Sensitivity (Maximum Statistic):** The script is set to look for the **Maximum** drift found across *any* of your data features. This means if even one single variable (like \"user age\" or \"transaction amount\") goes out of bounds, the alarm will trigger.\n",
        "\n",
        "### 3. The \"Line in the Sand\" (The Threshold)\n",
        "\n",
        "The system establishes a clear boundary for what is considered \"acceptable\" data.\n",
        "\n",
        "* **The Threshold (1.0):** This is the limit. In SageMaker, a drift score of **1.0** typically represents a significant violation of the rules established during the model's setup.\n",
        "* **Evaluation Frequency:** The system checks the data in **1-hour blocks**. If the drift hits the limit at any point during that hour, the alarm is raised immediately.\n",
        "\n",
        "### 4. Automated Notification and Recovery\n",
        "\n",
        "Monitoring is only useful if someone is notified. This script connects the alarm to a notification service (SNS).\n",
        "\n",
        "* **The Alert:** As soon as the drift exceeds the limit, a message is sent to a specific \"Topic\" (which can forward it to an email, a Slack channel, or a pager).\n",
        "* **The \"All Clear\":** Importantly, the script also sends a notification when the data returns to normal (**OKActions**). This tells the team that the issue has been resolved and the model's data is healthy again.\n"
      ],
      "metadata": {
        "id": "Csa59-I4UZhh"
      },
      "id": "Csa59-I4UZhh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f6e678-ecf1-4ad7-86c8-88ee1b14486a",
      "metadata": {
        "id": "d4f6e678-ecf1-4ad7-86c8-88ee1b14486a",
        "outputId": "3cb40a8d-fd69-4c49-9720-3dd919afe8a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Alarm 'ueba-endpoint2026216-v2-FeatureDrift' created.\n"
          ]
        }
      ],
      "source": [
        "# II. Automated Data Quality and Feature Drift Monitoring\n",
        "\n",
        "import boto3\n",
        "\n",
        "cloudwatch = boto3.client('cloudwatch')\n",
        "endpoint_name = \"ueba-endpoint2026216-v2\"\n",
        "alarm_name = f\"{endpoint_name}-FeatureDrift\"\n",
        "sns_topic_arn = \"arn:aws:sns:us-east-1:805801076223:YourSNSTopic\"  # <-- Replace\n",
        "\n",
        "cloudwatch.put_metric_alarm(\n",
        "    AlarmName=alarm_name,\n",
        "    AlarmDescription=f'Alarm when feature drift is detected for endpoint {endpoint_name}',\n",
        "    ActionsEnabled=True,\n",
        "    OKActions=[sns_topic_arn],\n",
        "    AlarmActions=[sns_topic_arn],\n",
        "    MetricName='feature_baseline_drift',\n",
        "    Namespace='aws/sagemaker/Endpoints/data-quality',\n",
        "    Statistic='Maximum',\n",
        "    Dimensions=[\n",
        "        {'Name': 'EndpointName', 'Value': endpoint_name}\n",
        "    ],\n",
        "    Period=3600,          # 1 hour (matching monitoring frequency)\n",
        "    EvaluationPeriods=1,\n",
        "    Threshold=1.0,\n",
        "    ComparisonOperator='GreaterThanOrEqualToThreshold'\n",
        ")\n",
        "print(f\"✅ Alarm '{alarm_name}' created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Automated Fairness and Bias Monitoring for AI Models\n",
        "\n",
        "This script establishes a \"safety corridor\" for an Artificial Intelligence model to ensure it treats different groups of people fairly. It specifically monitors **Disparate Impact (DI)**, a standard metric used to detect bias in automated decision-making.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. The Core Objective: Protecting Fairness\n",
        "\n",
        "The goal of this code is to ensure the model does not develop a \"bias\" against a particular group (such as gender, age, or ethnicity) over time. In data science, perfect fairness is represented by a value of **1.0**. If the value shifts too far in either direction, it indicates the model is favoring one group over another.\n",
        "\n",
        "### 2. The \"Safety Corridor\" Strategy\n",
        "\n",
        "Unlike a simple alarm that only watches for a single problem, this script sets up two separate \"guards\" to catch bias in both directions:\n",
        "\n",
        "* **The Lower Boundary (0.8):** If the fairness metric drops below 0.8, it suggests a group is receiving significantly fewer favorable outcomes than others.\n",
        "* **The Upper Boundary (1.25):** If the metric rises above 1.25, it suggests the opposite—one group is being disproportionately favored compared to the rest.\n",
        "\n",
        "By setting these two limits, the script ensures the model operates within a legally and ethically accepted \"safe zone.\"\n",
        "\n",
        "### 3. Continuous Vigilance and Verification\n",
        "\n",
        "The system doesn't just check once; it provides ongoing surveillance of the live model environment.\n",
        "\n",
        "* **Hourly Checks:** The system averages the model's behavior every hour to ensure the data is statistically significant.\n",
        "* **Instant Reaction:** If the model's behavior falls outside the 0.8–1.25 range for even a single hour, the system immediately flags it as an issue.\n",
        "\n",
        "### 4. Incident Response and Recovery\n",
        "\n",
        "The script automates the communication process so that human engineers can intervene as soon as a bias is detected.\n",
        "\n",
        "* **The Alert System:** If the model becomes biased, an automated notification is sent to a specific team or dashboard (via the SNS notification service).\n",
        "* **The Recovery Signal:** If the model is retuned or the data stabilizes, the system sends a second notification confirming that the model is back within the fair \"safe zone.\"\n",
        "\n",
        "### 5. Targeting the Model Source\n",
        "\n",
        "The script is precision-targeted to a specific project. It identifies the exact \"location\" of the live model and looks specifically at the **Model Bias** logs. This ensures that the fairness monitoring is tied directly to the specific AI service being used for decision-making.\n"
      ],
      "metadata": {
        "id": "mTV-HrAjTl-p"
      },
      "id": "mTV-HrAjTl-p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3374ef01-22e8-45cf-9b33-189d56283fdd",
      "metadata": {
        "id": "3374ef01-22e8-45cf-9b33-189d56283fdd",
        "outputId": "97534862-6bce-4cec-962b-dc87643e4398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Bias alarms created: ueba-endpoint2026216-v2-DI-Low, ueba-endpoint2026216-v2-DI-High\n"
          ]
        }
      ],
      "source": [
        "# III. Automated Fairness and Bias Monitoring for AI Models\n",
        "\n",
        "import boto3\n",
        "\n",
        "cloudwatch = boto3.client('cloudwatch')\n",
        "endpoint_name = \"ueba-endpoint2026216-v2\"\n",
        "alarm_name_low = f\"{endpoint_name}-DI-Low\"\n",
        "alarm_name_high = f\"{endpoint_name}-DI-High\"\n",
        "sns_topic_arn = \"arn:aws:sns:us-east-1:805801076223:YourSNSTopic\"  # <-- Replace\n",
        "\n",
        "# Alarm for DI below 0.8\n",
        "cloudwatch.put_metric_alarm(\n",
        "    AlarmName=alarm_name_low,\n",
        "    AlarmDescription=f'Alarm when Disparate Impact drops below 0.8 for {endpoint_name}',\n",
        "    ActionsEnabled=True,\n",
        "    OKActions=[sns_topic_arn],\n",
        "    AlarmActions=[sns_topic_arn],\n",
        "    MetricName='DI',          # or 'disparate_impact' – check your metrics\n",
        "    Namespace='aws/sagemaker/Endpoints/model-bias',\n",
        "    Statistic='Average',\n",
        "    Dimensions=[\n",
        "        {'Name': 'EndpointName', 'Value': endpoint_name}\n",
        "        # You may also need to add dimensions for facet, label, etc.\n",
        "    ],\n",
        "    Period=3600,\n",
        "    EvaluationPeriods=1,\n",
        "    Threshold=0.8,\n",
        "    ComparisonOperator='LessThanThreshold'\n",
        ")\n",
        "\n",
        "# Alarm for DI above 1.25\n",
        "cloudwatch.put_metric_alarm(\n",
        "    AlarmName=alarm_name_high,\n",
        "    AlarmDescription=f'Alarm when Disparate Impact exceeds 1.25 for {endpoint_name}',\n",
        "    ActionsEnabled=True,\n",
        "    OKActions=[sns_topic_arn],\n",
        "    AlarmActions=[sns_topic_arn],\n",
        "    MetricName='DI',\n",
        "    Namespace='aws/sagemaker/Endpoints/model-bias',\n",
        "    Statistic='Average',\n",
        "    Dimensions=[\n",
        "        {'Name': 'EndpointName', 'Value': endpoint_name}\n",
        "    ],\n",
        "    Period=3600,\n",
        "    EvaluationPeriods=1,\n",
        "    Threshold=1.25,\n",
        "    ComparisonOperator='GreaterThanThreshold'\n",
        ")\n",
        "\n",
        "print(f\"✅ Bias alarms created: {alarm_name_low}, {alarm_name_high}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IV. Automated Monitoring for Machine Learning Model Reliability - Explainability Monitor\n",
        "\n",
        "This script sets up a \"digital security guard\" for an Artificial Intelligence model. Specifically, it focuses on **Model Explainability**, which ensures that the reasons behind a model's decisions (like why it flagged a specific user as a security risk) remain consistent and logical over time.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. The Core Objective: Detecting \"Drift\"\n",
        "\n",
        "In machine learning, \"drift\" happens when a model starts behaving differently than it did during its initial training. This code specifically monitors **Explainability Drift**.\n",
        "\n",
        "If the model suddenly starts prioritizing different data features to reach its conclusions—for example, if a fraud detection model suddenly stops looking at \"transaction location\" and starts looking only at \"account age\"—this is a red flag. This script is designed to catch that shift automatically.\n",
        "\n",
        "### 2. Setting the \"Line in the Sand\" (The Threshold)\n",
        "\n",
        "The system is configured to watch a specific data metric that measures this shift. It establishes a mathematical boundary (a threshold).\n",
        "\n",
        "* **Monitoring Frequency:** The system checks the health of the model every hour.\n",
        "* **Sensitivity:** It is set to be highly responsive. If even a single one-hour window shows that the model’s internal logic has shifted beyond the allowed limit, the alarm is triggered immediately.\n",
        "\n",
        "### 3. The Notification Pipeline (SNS)\n",
        "\n",
        "Monitoring is useless if no one knows there is a problem. The script connects the alarm to a notification service.\n",
        "\n",
        "* **When things go wrong:** If the \"drift\" exceeds the limit, an alert is broadcast to a specific communication channel (like an email list or a DevOps chat).\n",
        "* **When things are fixed:** The system also sends a \"Clear\" signal once the model's logic returns to its normal, expected baseline.\n",
        "\n",
        "### 4. Target Identification\n",
        "\n",
        "The script isn't just watching everything; it is laser-focused on a specific **SageMaker Endpoint** (the live environment where the AI lives). It identifies the exact \"address\" of the model and the specific category of logs where the explainability data is stored, ensuring that the alarm only reacts to the relevant machine learning project.\n"
      ],
      "metadata": {
        "id": "y5HnpaxgS-00"
      },
      "id": "y5HnpaxgS-00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfdb928-89bc-4cce-a816-0bb011bd4a41",
      "metadata": {
        "id": "4bfdb928-89bc-4cce-a816-0bb011bd4a41",
        "outputId": "37816f3c-4773-442a-82dd-3ccb03736d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Alarm 'ueba-endpoint2026216-v2-ExplainabilityDrift' created.\n"
          ]
        }
      ],
      "source": [
        "# IV. Automated Monitoring for Machine Learning Model Reliability - Explainability Monitor\n",
        "\n",
        "import boto3\n",
        "\n",
        "cloudwatch = boto3.client('cloudwatch')\n",
        "endpoint_name = \"ueba-endpoint2026216-v2\"\n",
        "alarm_name = f\"{endpoint_name}-ExplainabilityDrift\"\n",
        "sns_topic_arn = \"arn:aws:sns:us-east-1:805801076223:YourSNSTopic\"  # <-- Replace\n",
        "\n",
        "cloudwatch.put_metric_alarm(\n",
        "    AlarmName=alarm_name,\n",
        "    AlarmDescription=f'Alarm when explainability drift is detected for {endpoint_name}',\n",
        "    ActionsEnabled=True,\n",
        "    OKActions=[sns_topic_arn],\n",
        "    AlarmActions=[sns_topic_arn],\n",
        "    MetricName='shap_drift',          # Replace with actual metric name\n",
        "    Namespace='aws/sagemaker/Endpoints/model-explainability',\n",
        "    Statistic='Average',\n",
        "    Dimensions=[\n",
        "        {'Name': 'EndpointName', 'Value': endpoint_name}\n",
        "    ],\n",
        "    Period=3600,\n",
        "    EvaluationPeriods=1,\n",
        "    Threshold=1.0,                     # Adjust based on your baseline\n",
        "    ComparisonOperator='GreaterThanOrEqualToThreshold'\n",
        ")\n",
        "print(f\"✅ Alarm '{alarm_name}' created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91b7da6-56ae-4e04-8a20-33d36c138d78",
      "metadata": {
        "id": "c91b7da6-56ae-4e04-8a20-33d36c138d78"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow2_p310",
      "language": "python",
      "name": "conda_tensorflow2_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}